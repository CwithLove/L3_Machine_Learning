{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet: Modèles linéaires:  Adaline et Regression Logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons nous intéresser à l'implémentation d'un algorithme de descente de gradient pour trouver le meilleur paramètre d'un module Adaline ou de regression logistique.\n",
    "\n",
    "Pout cela, on implémentera un algorithme de descente de gradient stochastique que nous avons vu au TP précédent et dont le pseudo-code peut être résumé comme suit:\n",
    "\n",
    "```input: Train, eta, m, MaxEp, modele\n",
    "init : w\n",
    "epoque=0\n",
    "while epoque<=MaxEp\n",
    "    choisir un exemple (x,y) de Train de façon aléatoire\n",
    "    calculer h = w*x\n",
    "    calculer Loss(h, y)\n",
    "    w <- w - eta*\"gradient de Loss(h, y) par rapport à w\"\n",
    "    epoque <- epoque+1\n",
    "output: w\n",
    "```\n",
    "où \"eta\" est le pas de la descente de gradient (exemple: eta=0.01).\n",
    "\n",
    "Si on veut imprimer l'erreur tous les \"m\" pas de gradient:\n",
    "```input: Train, eta, m, MaxEp, modele\n",
    "init : w\n",
    "epoque=0\n",
    "while epoque<=MaxEp\n",
    "    err = 0\n",
    "    for i in range(m):\n",
    "        choisir un exemple (x,y) de Train de façon aléatoire\n",
    "        calculer h = w*x\n",
    "        err += Loss(h, y)\n",
    "        w <- w - eta*\"gradient de Loss(h, y) par rapport à w\"\n",
    "    epoque <- epoque+1\n",
    "    print(err)\n",
    "output: w\n",
    "```\n",
    "\n",
    "Pour un poids $w$, on définit $h_\\mathbf{w}(\\mathbf{x})=w_0x_0+w_1x_1+...w_dx_d$. Pour chacun des deux modèles, et pour un exemple $(\\mathbf{x},y)$, la prédiction $\\hat{y}(\\mathbf{w}, \\mathbf{x})$ et la fonction de coût  $\\mathcal{L}(\\mathbf{w}, \\mathbf{x})$ sont: \n",
    "- Adaline: $\\hat{y}(\\mathbf{w}, \\mathbf{x}) = h_\\mathbf{w}(x)$ et $$\\mathcal{L}(\\mathbf{w})=(y-\\hat{y}(\\mathbf{w},\\mathbf{x}))^2=(y-h_\\mathbf{w}(\\mathbf{x}))^2,$$\n",
    "- Régression logistique: $\\hat{y}(w, x) = 1/(1+e^{-h_{\\mathbf{w}}(\\mathbf{x})})$ et $$\\mathcal{L}(\\mathbf{w}, x) = - y \\log \\hat{y}(\\mathbf{w},\\mathbf{x}) - (1-y)\\log(1-\\hat{y}(\\mathbf{w},\\mathbf{x})) = \\log(1+e^{h_{\\mathbf{w}}(\\mathbf{x})})-yh_\\mathbf{w}(\\mathbf{x}),$$\n",
    "\n",
    "Nous avons vu les gradients de ces fonctions en TD.\n",
    "\n",
    "## Partie 1: implémentation de l'algorithme et exemple du \"ET logique\"\n",
    "\n",
    "<font color='red'><b>Question 1:</b> le \"ET logique\".</font> Créer une liste de 4 éléments où chaque élément est un couple de la forme `[x,y]`, avec `x=[1,x1,x2]` et `y = x1 and x2`. Il y a 4 éléments car `x1` et `x2` peuvent chacun prendre la valeur `0` ou `1` (chacun de ces 4 éléments est une liste dont le premier élément est les attributs de l'exemple et le deuxième élément est la classe de l'exemple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = [0] * 4\n",
    "for x1 in range(2):\n",
    "    for x2 in range(2):\n",
    "        liste[x1*1+x2*2] = [[1,x1,x2], x1 and x2] \n",
    "\n",
    "X = np.array([x[0] for x in liste])\n",
    "Y = np.array([x[1] for x in liste])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'><b>Question 2:</b></font> Coder le modèle Adaline et le modèle de régression logistique et le faire tourner sur le modèle de \"ET logique\". Calculer le taux d'erreur de votre algorithme sur cette base (où une erreur est comptabilisé si la prédiction est plus proche de la fausse classe que de la vraie classe). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final weights for Adaline on 'ET logique': [0.07363179 0.20286703 0.20334775]\n",
      "Final weights for Logistic Regression on 'ET logique': [-1.91734769  0.95139012  1.21639291]\n",
      "Training Adaline...\n",
      "Error rate: 0.25\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.25\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.25\n",
      "Error rate: 0.25\n",
      "Error rate: 0.25\n",
      "Error rate: 0.0\n",
      "Error rate: 0.25\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Training Logistic Regression...\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.25\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n",
      "Error rate: 0.0\n"
     ]
    }
   ],
   "source": [
    "import random as rd\n",
    "\n",
    "# Adaline\n",
    "def h(w,x):\n",
    "    return w@x\n",
    "\n",
    "def loss_adaline(p,y):\n",
    "    return (y-p)**2\n",
    "\n",
    "def adaline_grad(w,x,y):\n",
    "    return 2*(h(w,x) - y)*x\n",
    "\n",
    "# Regression logistique\n",
    "def prediction_regression_logistique(w,x):\n",
    "    return 1/(1 + np.exp(-h(w,x)))\n",
    "\n",
    "def loss_regression_logistique(p,y):\n",
    "    p = np.clip(p, 1e-10, 1-1e-10)\n",
    "    return -y*np.log(p) - (1-y)*np.log(1-p)\n",
    "\n",
    "def regression_logistique_grad(w,x,y):\n",
    "    return (prediction_regression_logistique(w,x)-y)*x\n",
    "\n",
    "# Gradient\n",
    "def gradient(grad, w, x, y):\n",
    "    return grad(w,x,y)\n",
    "\n",
    "# Learning rate    \n",
    "def eta_001(t):\n",
    "    return 0.01\n",
    "\n",
    "def eta_01(t):\n",
    "    return 0.1\n",
    "    \n",
    "# Stochastic Gradient Descent\n",
    "def SGD(X, Y, Maxep, eta, p, loss_function, g, err_printing=True):\n",
    "    w = np.random.rand(len(X[0])) * 0.01\n",
    "    for epoque in range(Maxep):\n",
    "        i = rd.randint(0, len(Y) - 1)\n",
    "        pred = p(w, X[i])\n",
    "        if err_printing:\n",
    "            print(loss_function(pred, Y[i]))\n",
    "        w = w - eta(epoque) * g(w, X[i], Y[i])\n",
    "    return w\n",
    "\n",
    "def SGD_with_error_printing(X, Y, Maxep, eta, m, p, loss_function, g, err_printing=True):\n",
    "    w = np.random.rand(len(X[0])) * 0.01\n",
    "    for epoque in range(Maxep):\n",
    "        err = 0\n",
    "        for _ in range(m):\n",
    "            i = rd.randint(0, len(Y) - 1)\n",
    "            pred = p(w, X[i])\n",
    "            err += loss_function(pred, Y[i])\n",
    "            w = w - eta(epoque) * g(w, X[i], Y[i])\n",
    "        if err_printing:\n",
    "            print(\"epoque \", epoque, \": \", err)\n",
    "    return w\n",
    "\n",
    "# Training Adaline on \"ET logique\"\n",
    "w_adaline = SGD(X, Y, 100, eta_001, h, loss_adaline, adaline_grad, False)\n",
    "print(\"Final weights for Adaline on 'ET logique':\", w_adaline)\n",
    "# Training Logistic Regression on \"ET logique\"\n",
    "w_logistic = SGD_with_error_printing(X, Y, 100, eta_01, 2, prediction_regression_logistique, loss_regression_logistique, regression_logistique_grad, False)\n",
    "print(\"Final weights for Logistic Regression on 'ET logique':\", w_logistic)\n",
    "\n",
    "def calculate_error_rate(w, X, Y, prediction_function, rate_printing=False):\n",
    "    errors = 0\n",
    "    for i in range(len(Y)):\n",
    "        pred = prediction_function(w, X[i])\n",
    "        if rate_printing:\n",
    "            print(f\"P: {pred}, Y: {Y[i]}\")\n",
    "        if (pred >= 0.5 and Y[i] == 0) or (pred < 0.5 and Y[i] == 1):\n",
    "            errors += 1\n",
    "    return errors / len(Y)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to calculate error rate multiple times\n",
    "def calculate_multiple_error_rates(X, Y, num_iterations, model, prediction_function, eta, Maxep):\n",
    "    if model == 'adaline':\n",
    "        print(\"Training Adaline...\")\n",
    "    elif model == 'logistic':\n",
    "        print(\"Training Logistic Regression...\")\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        if model == 'adaline':\n",
    "            w = SGD(X, Y, Maxep, eta, h, loss_adaline, adaline_grad, False)\n",
    "        elif model == 'logistic':\n",
    "            w = SGD(X, Y, Maxep, eta, prediction_regression_logistique, loss_regression_logistique, regression_logistique_grad, False)\n",
    "        error_rate = calculate_error_rate(w, X, Y, prediction_function, False)\n",
    "        print(\"Error rate:\", error_rate)\n",
    "\n",
    "\n",
    "# Calculate error rates for Adaline and Logistic Regression\n",
    "num_iterations = 20\n",
    "\n",
    "# calculate_multiple_error_rates(X, Y, num_iterations, 'adaline', h, eta_001, 100)\n",
    "calculate_multiple_error_rates(X, Y, num_iterations, 'adaline', h, eta_01, 100)\n",
    "# calculate_multiple_error_rates(X, Y, num_iterations, 'logistic', prediction_regression_logistique, eta_01, 100)\n",
    "# calculate_multiple_error_rates(X, Y, num_iterations, 'logistic', prediction_regression_logistique, eta_01, 200)\n",
    "calculate_multiple_error_rates(X, Y, num_iterations, 'logistic', prediction_regression_logistique, eta_01, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2: premiers tests avec une base de donnée réelle\n",
    "\n",
    "<font color='red'><b>Question 3:</b></font> Nous allons maintenant nous intéresser au comportement de ces modèles sur la base SONAR de la collection UCI (http://archive.ics.uci.edu/ml/index.php). Cette base contient 208 exemples en dimension 60 séparés par `,` et la dernière élément correspond à la classe de l'exemple.\n",
    "\n",
    "    1. Télécharger la collection avec la fonction read_table de la librairie pandas (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_table.html). Les options nécessaires sont `sep=','` et `header=None`  \n",
    "    2. Créer une liste de listes correspondant à la collection; pour cela initialiser la première liste et en parcourant chaque ligne de la matrice de données; créer une liste associée en remplaçant le dernier élément par `-1` ou `+1` et insérer la dans la première liste. \n",
    "    Indication: Utiliser la fonction `loc`. \n",
    "    3. Écrire une fonction qui génère deux listes de données `x_train` (75%) and `x_test` (25%) en la mélangeant aléatoirement au préalable (indication: on pourra utiliser les fonctions `shuffle` de la librairie `random` et `train_test_split` de la librairie `sklearn.model_selection`)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/Sonar/sonar.all-data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData/Sonar/sonar.all-data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(df), \u001b[38;5;241m60\u001b[39m))\n\u001b[1;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m208\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/readers.py:683\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, encoding_errors, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    668\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    669\u001b[0m     dialect,\n\u001b[1;32m    670\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    679\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    680\u001b[0m )\n\u001b[1;32m    681\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/readers.py:482\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    479\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/readers.py:811\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/readers.py:1040\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown engine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (valid options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1038\u001b[0m     )\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/c_parser_wrapper.py:51\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     48\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# open handles\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Have to pass int, would break tests using TextReader directly otherwise :(\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/base_parser.py:222\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_handles\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: FilePathOrBuffer, kwds: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    Let the readers open IOHandles after they are done with their potential raises.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/common.py:702\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 702\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    711\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/Sonar/sonar.all-data'"
     ]
    }
   ],
   "source": [
    "df = pd.read_table('Data/Sonar/sonar.all-data', sep = ',', header = None)\n",
    "\n",
    "x = np.zeros((len(df), 60))\n",
    "y = np.zeros(208)\n",
    "\n",
    "for i in range(60):\n",
    "    x[:,i] = df[i]\n",
    "\n",
    "for i in range(208):\n",
    "    if df[60][i] == 'R': y[i] = 1\n",
    "    elif df[60][i]: y[i] = -1\n",
    "\n",
    "def generate_train_test_random(x, y):\n",
    "    data = list(zip(x, y))\n",
    "    rd.shuffle(data)\n",
    "    new_X = np.array([i for i, j in data])\n",
    "    new_Y = np.array([j for i, j in data])\n",
    "    x_train, x_test, y_train, y_test = train_test_split(new_X, new_Y, test_size=0.25)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'><b>Question 4:</b></font> Appliquer ces modèles sur cette base en prenant comme $MaxEp=500$, le pas d'apprentissage $\\eta=0.1$ et en choisissant les bases Train et Test de façon aléatoire; Reporter l'erreur moyenne de ces modèles obtenues sur les 20 bases Test?  Refaire l'opération 3 fois avec trois randomisations différentes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0:\n",
      "Training Adaline on sonar data...\n",
      "Error rate: 0.6793767875654334\n",
      "Training Logistic Regression on sonar data...\n",
      "Error rate: 1.7037236989932638\n",
      "\n",
      "iter 1:\n",
      "Training Adaline on sonar data...\n",
      "Error rate: 0.661833072347028\n",
      "Training Logistic Regression on sonar data...\n",
      "Error rate: -0.8856096510477097\n",
      "\n",
      "iter 2:\n",
      "Training Adaline on sonar data...\n",
      "Error rate: 0.733417493827009\n",
      "Training Logistic Regression on sonar data...\n",
      "Error rate: -0.8856096510477098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MaxEp = 500\n",
    "\n",
    "for _ in range(3):\n",
    "    x_train, x_test, y_train, y_test = generate_train_test_random(x, y)\n",
    "    out = \"iter \" + str(_) + \":\\n\"   \n",
    "    out += \"Training Adaline on sonar data...\\n\"\n",
    "    w_adaline = SGD(x_train, y_train, MaxEp, eta_001, h, loss_adaline, adaline_grad, False)\n",
    "    error_rate = []\n",
    "    for x_i, y_i in zip(x_test, y_test):\n",
    "        error_rate.append(loss_adaline(h(w_adaline, x_i), y_i))\n",
    "    out += \"Error rate: \" + str(np.mean(error_rate)) + \"\\n\"\n",
    "    \n",
    "    out += \"Training Logistic Regression on sonar data...\\n\"\n",
    "    w_logistic = SGD(x_train, y_train, MaxEp, eta_01, prediction_regression_logistique, loss_regression_logistique, regression_logistique_grad, False)\n",
    "    error_rate = []\n",
    "    for x_i, y_i in zip(x_test, y_test):\n",
    "        error_rate.append(loss_regression_logistique(prediction_regression_logistique(w_logistic, x_i), y_i))\n",
    "    out += \"Error rate: \" + str(np.mean(error_rate)) + \"\\n\"\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  | Collection | Adaline     | Régression Logistique |\n",
    "  |------------|-------------|-----------------------|\n",
    "  |   SONAR (réplica 1)   |             |                       |\n",
    "  |   SONAR (réplica 2)   |             |                       |\n",
    "  |   SONAR (réplica 3)   |             |                       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3: normalisation\n",
    "\n",
    "Nous allons étudier l'impact de la nomralisation sur les prédictions. Pour cela nous considérons deux stratégies de normalisation communément utilisées dans la littérature:\n",
    "* Stratégie <i>max</i>: consiste à normaliser chaque caractéristique du vecteur réprésentatif d'une observation par la valeur maximale de cette caractéristiques\n",
    "* Stratégie <i>norme</i>: consiste à normaliser chaque caractéristique du vecteur réprésentatif d'une observation par la norme de ce vecteur.\n",
    "\n",
    "Nous considérons ces trois autres collections de la base UCI:\n",
    "\n",
    "        * https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "        * https://archive.ics.uci.edu/ml/datasets/spambase\n",
    "        * https://archive.ics.uci.edu/ml/datasets/ionosphere\n",
    "\n",
    "<font color='red'><b>Question 5:</b></font> Ecrire une fonction qui prend en entrée la collection des données et qui retourne la collections normalisée suivant les stratégies <i>max</i> et <i>norme</i>. \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0  1         2         3         4         5         6         7   \\\n",
      "0    0.000275  M  0.051800  0.022019  0.054122  0.056456  0.050972  0.099531   \n",
      "1    0.000275  M  0.059229  0.037695  0.058573  0.074786  0.036481  0.028196   \n",
      "2    0.027492  M  0.056695  0.045078  0.057295  0.067849  0.047183  0.057331   \n",
      "3    0.027507  M  0.032883  0.043232  0.034192  0.021776  0.061347  0.101790   \n",
      "4    0.027511  M  0.058423  0.030419  0.059543  0.073150  0.043179  0.047614   \n",
      "..        ... ..       ...       ...       ...       ...       ...       ...   \n",
      "564  0.000302  M  0.062079  0.047496  0.062584  0.083415  0.047786  0.041555   \n",
      "565  0.000302  M  0.057962  0.059927  0.057824  0.071120  0.042103  0.037073   \n",
      "566  0.000302  M  0.047798  0.059566  0.047731  0.048396  0.036399  0.036679   \n",
      "567  0.000302  M  0.059315  0.062218  0.061747  0.071345  0.050713  0.099316   \n",
      "568  0.000030  B  0.022344  0.052057  0.021120  0.010208  0.022657  0.015640   \n",
      "\n",
      "           8         9   ...        22        23        24        25  \\\n",
      "0    0.105467  0.098797  ...  0.062695  0.027518  0.068855  0.080738   \n",
      "1    0.030540  0.047128  ...  0.061732  0.037172  0.059232  0.078218   \n",
      "2    0.069374  0.085901  ...  0.058224  0.040539  0.056882  0.068341   \n",
      "3    0.084838  0.070655  ...  0.036832  0.042079  0.036878  0.022702   \n",
      "4    0.069585  0.070051  ...  0.055680  0.026470  0.056770  0.062983   \n",
      "..        ...       ...  ...       ...       ...       ...       ...   \n",
      "564  0.085716  0.093289  ...  0.062868  0.041920  0.061955  0.081058   \n",
      "565  0.050607  0.065759  ...  0.058521  0.060736  0.057815  0.069221   \n",
      "566  0.032512  0.035610  ...  0.046886  0.054179  0.047259  0.044948   \n",
      "567  0.123496  0.102087  ...  0.063585  0.062594  0.068855  0.072820   \n",
      "568  0.000000  0.000000  ...  0.023359  0.048224  0.022067  0.010741   \n",
      "\n",
      "           26        27        28        29        30        31  \n",
      "0    0.050624  0.093343  0.087052  0.084232  0.065034  0.058052  \n",
      "1    0.038639  0.026169  0.029543  0.059032  0.038871  0.043463  \n",
      "2    0.045068  0.059531  0.055076  0.077122  0.051069  0.042760  \n",
      "3    0.065480  0.121489  0.083995  0.081724  0.093827  0.084466  \n",
      "4    0.042883  0.028749  0.048913  0.051574  0.033415  0.037487  \n",
      "..        ...       ...       ...       ...       ...       ...  \n",
      "564  0.044007  0.029632  0.050221  0.070331  0.029118  0.034738  \n",
      "565  0.036392  0.026954  0.039314  0.051669  0.036355  0.032405  \n",
      "566  0.035549  0.043390  0.041612  0.045004  0.031351  0.038181  \n",
      "567  0.051498  0.121741  0.114786  0.084105  0.057769  0.060542  \n",
      "568  0.028077  0.009037  0.000000  0.000000  0.040581  0.034367  \n",
      "\n",
      "[569 rows x 32 columns]\n",
      "           0  1         2         3         4         5         6         7   \\\n",
      "0    0.000275  M  0.051800  0.022019  0.054122  0.056456  0.050972  0.099531   \n",
      "1    0.000275  M  0.059229  0.037695  0.058573  0.074786  0.036481  0.028196   \n",
      "2    0.027492  M  0.056695  0.045078  0.057295  0.067849  0.047183  0.057331   \n",
      "3    0.027507  M  0.032883  0.043232  0.034192  0.021776  0.061347  0.101790   \n",
      "4    0.027511  M  0.058423  0.030419  0.059543  0.073150  0.043179  0.047614   \n",
      "..        ... ..       ...       ...       ...       ...       ...       ...   \n",
      "564  0.000302  M  0.062079  0.047496  0.062584  0.083415  0.047786  0.041555   \n",
      "565  0.000302  M  0.057962  0.059927  0.057824  0.071120  0.042103  0.037073   \n",
      "566  0.000302  M  0.047798  0.059566  0.047731  0.048396  0.036399  0.036679   \n",
      "567  0.000302  M  0.059315  0.062218  0.061747  0.071345  0.050713  0.099316   \n",
      "568  0.000030  B  0.022344  0.052057  0.021120  0.010208  0.022657  0.015640   \n",
      "\n",
      "           8         9   ...        22        23        24        25  \\\n",
      "0    0.105467  0.098797  ...  0.062695  0.027518  0.068855  0.080738   \n",
      "1    0.030540  0.047128  ...  0.061732  0.037172  0.059232  0.078218   \n",
      "2    0.069374  0.085901  ...  0.058224  0.040539  0.056882  0.068341   \n",
      "3    0.084838  0.070655  ...  0.036832  0.042079  0.036878  0.022702   \n",
      "4    0.069585  0.070051  ...  0.055680  0.026470  0.056770  0.062983   \n",
      "..        ...       ...  ...       ...       ...       ...       ...   \n",
      "564  0.085716  0.093289  ...  0.062868  0.041920  0.061955  0.081058   \n",
      "565  0.050607  0.065759  ...  0.058521  0.060736  0.057815  0.069221   \n",
      "566  0.032512  0.035610  ...  0.046886  0.054179  0.047259  0.044948   \n",
      "567  0.123496  0.102087  ...  0.063585  0.062594  0.068855  0.072820   \n",
      "568  0.000000  0.000000  ...  0.023359  0.048224  0.022067  0.010741   \n",
      "\n",
      "           26        27        28        29        30        31  \n",
      "0    0.050624  0.093343  0.087052  0.084232  0.065034  0.058052  \n",
      "1    0.038639  0.026169  0.029543  0.059032  0.038871  0.043463  \n",
      "2    0.045068  0.059531  0.055076  0.077122  0.051069  0.042760  \n",
      "3    0.065480  0.121489  0.083995  0.081724  0.093827  0.084466  \n",
      "4    0.042883  0.028749  0.048913  0.051574  0.033415  0.037487  \n",
      "..        ...       ...       ...       ...       ...       ...  \n",
      "564  0.044007  0.029632  0.050221  0.070331  0.029118  0.034738  \n",
      "565  0.036392  0.026954  0.039314  0.051669  0.036355  0.032405  \n",
      "566  0.035549  0.043390  0.041612  0.045004  0.031351  0.038181  \n",
      "567  0.051498  0.121741  0.114786  0.084105  0.057769  0.060542  \n",
      "568  0.028077  0.009037  0.000000  0.000000  0.040581  0.034367  \n",
      "\n",
      "[569 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "BreastCancer = pd.read_table('Data/BreastCancer/wdbc.data', header=None, sep=',')\n",
    "Ionosphere = pd.read_csv('Data/Ionosphere/ionosphere.data', header=None, sep=',')\n",
    "Spambase = pd.read_csv('Data/Spambase/spambase.data', header=None, sep=',')\n",
    "\n",
    "def normalizer_collection(collection, strategies = 'max'):\n",
    "    collection_clone = collection.select_dtypes(include=[np.number]).astype(float).copy()\n",
    "    \n",
    "    if strategies == 'max':\n",
    "        max_value = np.max(np.abs(collection_clone), axis=0)\n",
    "        max_value[max_value == 0] = 1\n",
    "        collection_clone = collection_clone / max_value\n",
    "    elif strategies == 'norme':\n",
    "        normes = np.linalg.norm(collection_clone, axis=0)\n",
    "        normes[normes == 0] = 1\n",
    "        collection_clone = collection_clone / normes\n",
    "    else:\n",
    "        raise ValueError(\"Invalid normalization strategy\")\n",
    "\n",
    "    collection[collection_clone.columns] = collection_clone\n",
    "    return collection\n",
    "\n",
    "BreastCancer_normalized_max = normalizer_collection(BreastCancer, strategies='max')\n",
    "BreastCancer_normalized_norme = normalizer_collection(BreastCancer, strategies='norme')\n",
    "Ionosphere_normalized = normalizer_collection(Ionosphere)\n",
    "Spambase_normalized = normalizer_collection(Spambase)\n",
    "\n",
    "print(BreastCancer_normalized_max)\n",
    "print(BreastCancer_normalized_norme)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'><b>Question 6:</b></font> Compléter les tableaux comparatifs suivants en repertant les erreurs moyennes sur 20 lancements des modèles de l'Adaline et de la Régression Logistique et pour les trois cas:\n",
    "\n",
    " '*' Les vecteurs ne sont pas normalisés\n",
    "     \n",
    "  | Collection |   Adaline   |  Régression Logistique |\n",
    "  |------------|-------------|------------------------|\n",
    "  |   BREAST   |             |                        |\n",
    "  |   IONO     |             |                        |\n",
    "  |   SONAR    |             |                        |\n",
    "  |   SPAM     |             |                        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection non normalized\n"
     ]
    }
   ],
   "source": [
    "print(\"collection non normalized\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection normalized with norme\n"
     ]
    }
   ],
   "source": [
    "print(\"collection normalized with norme\")\n",
    "\n",
    "BreastCancer_normalized_norme = normalizer_collection(BreastCancer, strategies='norme')\n",
    "Ionosphere_normalized_norme = normalizer_collection(Ionosphere, strategies='norme')\n",
    "Spambase_normalized_norme = normalizer_collection(Spambase, strategies='norme')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " $^n$ Normalisation suivant la stratégie <i>norme</i>\n",
    "     \n",
    "  | Collection |   Adaline   |  Régression Logistique |\n",
    "  |------------|-------------|------------------------|\n",
    "  |   BREAST   |             |                        |\n",
    "  |   IONO     |             |                        |\n",
    "  |   SONAR    |             |                        |\n",
    "  |   SPAM     |             |                        |\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection normalized with max\n"
     ]
    }
   ],
   "source": [
    "print(\"collection normalized with max\")\n",
    "\n",
    "BreastCancer_normalized_max = normalizer_collection(BreastCancer, strategies='max')\n",
    "Ionosphere_normalized_max = normalizer_collection(Ionosphere, strategies='max')\n",
    "Spambase_normalized_max = normalizer_collection(Spambase, strategies='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $^m$ Normalisation suivant la stratégie <i>max</i>\n",
    "    \n",
    "  | Collection |   Adaline   |  Régression Logistique |\n",
    "  |------------|-------------|------------------------|\n",
    "  |   BREAST   |             |                        |\n",
    "  |   IONO     |             |                        |\n",
    "  |   SONAR    |             |                        |\n",
    "  |   SPAM     |             |                        |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
